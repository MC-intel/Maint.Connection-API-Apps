import os
import pandas as pd
from pdfminer.high_level import extract_text
import re
import time

def pdf_to_text(path):
    try:
        text = extract_text(path)
        if not text:
            raise ValueError("No text extracted from PDF.")

        # Parse the extracted text
        report_parts = text.split("Readings:")
        if len(report_parts) < 2:
            raise ValueError("Unable to find 'Readings:' section.")
        cleandata = report_parts[1].replace('\n\n', ',')

        if 'Unidirectional Flow Device Certification Report' in text:
          cleandata = cleandata.split("Area")[:1]
          cleandata = cleandata[0]

        if 'Biological Safety Cabinet Certification Report' in text:
          cleandata = cleandata.split("Method")[:1]
          cleandata = cleandata[0]
        
        # Extract numbers and compute average
        numbers_only = re.findall(r'\d+', cleandata)
        numbers_integers = [int(num) for num in numbers_only]
        avg = sum(numbers_integers) / len(numbers_integers) if numbers_integers else 0
        print(numbers_integers)
        time.sleep(1)

        # Extract dates and other information
        report_date_section = text.split("Report Date:")[1]
        repdate, _ = report_date_section.split("Retest Date:", 1)
        repdate = repdate.strip()

        retest_date_section = text.split("Retest Date:")[1]
        retdate, _ = retest_date_section.split("eData:", 1)
        retdate = retdate.strip()

        sap_section = text.split("SN:")[1]
        sap, _ = sap_section.split("Class", 1)
        sap = '30000000' + sap.strip().replace(' ', '')

        loc_section = text.split("Chesterfield, MO 63017")[1]
        loc = loc_section[3:10].replace('\n', '').strip()

        return {'Avg. Airflow': avg, 'CalDate': repdate, 'NextCal': retdate, 'Serial': sap, 'loc': loc}
    except Exception as e:
        print(f"Error processing file {path}: {e}")
        return None

def process_files(desktop_dir):
    all_data = []  # Use a list to collect data dicts

    if not os.path.exists(desktop_dir):
        print(f"The directory {desktop_dir} does not exist.")
        return pd.DataFrame()  # Return an empty DataFrame

    for filename in os.listdir(desktop_dir):
        file_path = os.path.join(desktop_dir, filename)
       
        if os.path.isfile(file_path) and filename.lower().endswith('.pdf'):
            print(f"Processing {filename}...")
            data = pdf_to_text(file_path)
           
            if data:
                all_data.append(data)
                print(f'Parsed {filename}')
            else:
                print(f'Skipping {filename} due to processing error.')
        else:
            print(f'Skipped {filename} (not a PDF or could not be read).')

    return pd.DataFrame(all_data)  # Convert the list of dicts to a DataFrame

def save_to_excel(all_data, desktop_dir):
    if all_data.empty:
        print("No data to save.")
        return

    excel_path = os.path.join(desktop_dir, 'HoodReport.xlsx')
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        for location in all_data['loc'].unique():
            df_loc = all_data[all_data['loc'] == location].drop(columns=['loc'])
            df_loc.to_excel(writer, sheet_name=location[:31], index=False)

    print(f"Excel file has been created at {excel_path} with data categorized by location.")
    time.sleep(3)

# Execution
if __name__ == "__main__":
    print("Enter Folder Path: ")
    desktop_dir = input().strip()
    all_data = process_files(desktop_dir)
    save_to_excel(all_data, desktop_dir)
